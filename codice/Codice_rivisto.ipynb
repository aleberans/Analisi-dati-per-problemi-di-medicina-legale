{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    handlers=[logging.FileHandler(filename='Punteggi_prova.log')])\n",
    "logger_prova = logging.getLogger('Risultati')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA</th>\n",
       "      <th>SESSO</th>\n",
       "      <th>ANNI</th>\n",
       "      <th>PESO</th>\n",
       "      <th>ALTEZZA</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Mezzo</th>\n",
       "      <th>Testa:Neurocranio</th>\n",
       "      <th>Testa:Splancnocranio</th>\n",
       "      <th>Testa:Telencefalo</th>\n",
       "      <th>...</th>\n",
       "      <th>Scheletro:Rachide-cervicale</th>\n",
       "      <th>Scheletro:Rachide-toracico</th>\n",
       "      <th>Scheletro:Rachide-lombare</th>\n",
       "      <th>Scheletro:Bacino-e-sacro</th>\n",
       "      <th>Scheletro:Complesso-sterno/claveo/costale</th>\n",
       "      <th>Tot Testa</th>\n",
       "      <th>Tot Torace</th>\n",
       "      <th>Tot Addome</th>\n",
       "      <th>Tot Scheletro</th>\n",
       "      <th>Totale</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERBALE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85567</th>\n",
       "      <td>1999-10-29</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>27.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85829</th>\n",
       "      <td>2000-01-14</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>26.291724</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85977</th>\n",
       "      <td>2000-03-10</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>27.887617</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86220</th>\n",
       "      <td>2000-06-14</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>23.733238</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86247</th>\n",
       "      <td>2000-06-22</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>24.740937</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              DATA  SESSO  ANNI  PESO  ALTEZZA        BMI  Mezzo  \\\n",
       "VERBALE                                                            \n",
       "85567   1999-10-29      0    81  84.0     1.75  27.428571      0   \n",
       "85829   2000-01-14      1    69  69.0     1.62  26.291724      1   \n",
       "85977   2000-03-10      1    71  67.0     1.55  27.887617      1   \n",
       "86220   2000-06-14      1    54  60.0     1.59  23.733238      1   \n",
       "86247   2000-06-22      1    78  69.0     1.67  24.740937      1   \n",
       "\n",
       "         Testa:Neurocranio  Testa:Splancnocranio  Testa:Telencefalo  ...  \\\n",
       "VERBALE                                                              ...   \n",
       "85567                    1                     0                  0  ...   \n",
       "85829                    4                     4                  4  ...   \n",
       "85977                    2                     0                  1  ...   \n",
       "86220                    4                     0                  0  ...   \n",
       "86247                    2                     0                  0  ...   \n",
       "\n",
       "         Scheletro:Rachide-cervicale  Scheletro:Rachide-toracico  \\\n",
       "VERBALE                                                            \n",
       "85567                              0                           3   \n",
       "85829                              0                           0   \n",
       "85977                              0                           0   \n",
       "86220                              0                           0   \n",
       "86247                              0                           0   \n",
       "\n",
       "         Scheletro:Rachide-lombare  Scheletro:Bacino-e-sacro  \\\n",
       "VERBALE                                                        \n",
       "85567                            0                         3   \n",
       "85829                            0                         0   \n",
       "85977                            0                         0   \n",
       "86220                            0                         0   \n",
       "86247                            0                         0   \n",
       "\n",
       "         Scheletro:Complesso-sterno/claveo/costale  Tot Testa  Tot Torace  \\\n",
       "VERBALE                                                                     \n",
       "85567                                            3          2           0   \n",
       "85829                                            4         20           7   \n",
       "85977                                            4          6           0   \n",
       "86220                                            4          5           3   \n",
       "86247                                            4          2           0   \n",
       "\n",
       "         Tot Addome  Tot Scheletro  Totale  \n",
       "VERBALE                                     \n",
       "85567             3              9      14  \n",
       "85829             1              4      32  \n",
       "85977             0              4      10  \n",
       "86220             2              4      14  \n",
       "86247             2              4       8  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_excel('IncidentiModificato.xlsx', sheet_name='Foglio1', index_col=0)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([    85567,     85829,     85977,     86220,     86247,     86421,\n",
       "           86839,     86876,     86878,     90056,\n",
       "       ...\n",
       "          101097,    101180,    101189,    101544,    101583,    101618,\n",
       "       '101288E', 'E-97586',       'X',      'X1'],\n",
       "      dtype='object', name='VERBALE', length=130)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "import time\n",
    "from random import seed\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tqdm.notebook import tnrange\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "model_to_string_extended = {SVC: 'SVC', DecisionTreeClassifier: 'DecisionTreeClassifier', RandomForestClassifier:'RandomForestClassifier', GaussianNB: 'GaussianNB', LinearDiscriminantAnalysis: 'LinearDiscriminantAnalysis', MLPClassifier: 'MLPClassifier'}\n",
    "\n",
    "def addestra_nuovo(model_class, X, y, model_selection_grid, num_fold_external, num_fold_internal, nome_dataset, logger_name=None, scaling=StandardScaler(), dim_reduction=None):\n",
    "    \n",
    "    ext_fold = StratifiedKFold(n_splits=num_fold_external, shuffle=True)\n",
    "    test_errors = []\n",
    "    for infer_indices, test_indices in ext_fold.split(X, y):\n",
    "        print('start fold', end=' ')\n",
    "        int_fold = StratifiedKFold(n_splits=num_fold_internal, shuffle=True)\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        date_inizio = datetime.datetime.now().strftime(\"%d.%b %Y %H:%M:%S\")\n",
    "        if logger_name is not None: logger_name.info(f'INIZIO ADDESTRAMENTO alle {date_inizio}') \n",
    "\n",
    "        X_std = scaling.fit_transform(X)  if scaling is not None else X\n",
    "\n",
    "        X_std = dim_reduction.fit_transform(X_std) if dim_reduction is not None else X_std\n",
    "        \n",
    "        clf = GridSearchCV(estimator=model_class(), param_grid=model_selection_grid, cv=int_fold, n_jobs=2)\n",
    "        clf.fit(X_std[infer_indices], y.values[infer_indices])\n",
    "        test_error = clf.best_estimator_.score(X_std[test_indices], y.values[test_indices])\n",
    "        print('model used: {}'.format(model_to_string_extended[model_class]))\n",
    "        print('best score: {:.3f}, best params: {}'.format(clf.best_score_, clf.best_params_), end=' ')\n",
    "        print('test error: {:.3f} end fold'.format(test_error))\n",
    "        test_errors.append(test_error)\n",
    "        \n",
    "        if logger_name is not None:\n",
    "            logger_name.info(f'DATASET: {nome_dataset}')\n",
    "            logger_name.info(f'MODEL: {model_to_string_extended[model_class]}')\n",
    "            logger_name.info(f'SCALER: {scaling}')\n",
    "            logger_name.info(f'RIDUZIONE DIMENSIONALITA {dim_reduction}')\n",
    "            logger_name.info(f'IPERPARAMETRI: {clf.best_params_}')\n",
    "            logger_name.info(f'TRAINING ERROR: {clf.best_score_}')\n",
    "            logger_name.info(f'TEST ERROR: {np.mean(test_error)}')\n",
    "\n",
    "        end_time = time.time()\n",
    "        data_fine = datetime.datetime.now().strftime(\"%d.%b %Y %H:%M:%S\")\n",
    "        if logger_name is not None:\n",
    "            logger_name.info(f'FINE ADDESTRAMENTO alle {data_fine}, tempo di calcolo totale in secondi: {end_time-start_time}')\n",
    "    \n",
    "        \n",
    "        \n",
    "    return np.mean(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total = dataset[['SESSO', 'ANNI', 'PESO', 'ALTEZZA', 'Tot Testa', 'Tot Torace', 'Tot Addome', 'Tot Scheletro']]\n",
    "y_total = dataset['Mezzo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [SVC, DecisionTreeClassifier, RandomForestClassifier, GaussianNB, LinearDiscriminantAnalysis, MLPClassifier]\n",
    "model_to_string = {SVC: 'SVC', DecisionTreeClassifier: 'DT', RandomForestClassifier:'RF', GaussianNB: 'NB', LinearDiscriminantAnalysis: 'LD', MLPClassifier: 'MLP'}\n",
    "\n",
    "c_space = np.logspace(-4, 3, 10)\n",
    "gamma_space = np.logspace(-4, 3, 10)\n",
    "\n",
    "model_selection_grid_SVC = [\n",
    "  {'C': c_space, 'kernel': ['linear'], 'gamma': ['auto']},\n",
    "  {'C': c_space, 'gamma': gamma_space, 'kernel': ['rbf']},\n",
    "  {'C': c_space, 'gamma': ['auto', 'scale'], 'kernel': ['rbf']},\n",
    "  {'C': c_space, 'degree': [2, 3, 5, 9], 'kernel': ['poly'], 'gamma': ['auto']},\n",
    " ]\n",
    "\n",
    "model_selection_grid_DT = {'criterion': ['gini', 'entropy'],\n",
    "                        'max_leaf_nodes': [None, 2, 5, 10, 50, 100],\n",
    "                        'max_features': [None, 'sqrt', 'log2'],\n",
    "                        'max_depth': [None, 2, 5, 10]}\n",
    "\n",
    "\n",
    "\n",
    "model_selection_grid_RF = {'n_estimators': [5, 10, 50, 100, 200],\n",
    "                        'criterion': ['gini', 'entropy'],\n",
    "                        'max_leaf_nodes': [None, 2, 5, 10, 50, 100],\n",
    "                        'max_features': [None, 'sqrt', 'log2'],\n",
    "                        'max_depth': [None, 2, 5, 10]}\n",
    "\n",
    "model_selection_grid_NB = {}\n",
    "model_selection_grid_LD = {}\n",
    "\n",
    "model_selection_grid_MLP = {'max_iter': [5000],\n",
    "                        'hidden_layer_sizes': [[2], [4], [6], [10], [20], [4, 4], [10, 10]],\n",
    "                        'activation': ['identity', 'logistic', 'tanh', 'relu']}\n",
    "\n",
    "grids = [model_selection_grid_SVC, model_selection_grid_DT, model_selection_grid_RF, model_selection_grid_NB, model_selection_grid_LD, model_selection_grid_MLP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import json\n",
    "\n",
    "def add_column_to_results_nuovo(result_dict, column_name, serialized_results_filename,\n",
    "                          X, y, models, grids, scaling=StandardScaler(), dim_reduction=None, logger_name=logger_prova):\n",
    "    \n",
    "    if column_name not in result_dict:\n",
    "        if os.path.exists(serialized_results_filename):\n",
    "            with open(serialized_results_filename, 'r') as fp:\n",
    "                saved_dict = json.load(fp)\n",
    "                if column_name in saved_dict:\n",
    "                    result_dict[column_name] = saved_dict[column_name]\n",
    "                else:\n",
    "                    result_dict[column_name] = {model_to_string[m]: np.mean(addestra_nuovo(m,\n",
    "                                                                             X,\n",
    "                                                                             y,\n",
    "                                                                             g,\n",
    "                                                                             5,\n",
    "                                                                             3,\n",
    "                                                                             scaling=scaling,\n",
    "                                                                             dim_reduction=dim_reduction,\n",
    "                                                                             nome_dataset=column_name,\n",
    "                                                                             logger_name=logger_name))\n",
    "                                                 for m, g in zip(models, grids)}\n",
    "                    with open(serialized_results_filename, 'w', encoding='utf-8') as fp:\n",
    "                        json.dump(result_dict, fp, ensure_ascii=False, indent=4)\n",
    "        #Se il file json non esiste ancora non fa nulla, ho aggiunto allora un ramo else che lo crea per la prima volta\n",
    "        else:\n",
    "            result_dict[column_name] = {model_to_string[m]: np.mean(addestra_nuovo(m,\n",
    "                                                                                 X,\n",
    "                                                                                 y,\n",
    "                                                                                 g,\n",
    "                                                                                 5,\n",
    "                                                                                 3,\n",
    "                                                                                 scaling=scaling,\n",
    "                                                                                 dim_reduction=dim_reduction,\n",
    "                                                                                 nome_dataset=column_name,\n",
    "                                                                                 logger_name=logger_name))\n",
    "                                                 for m, g in zip(models, grids)}\n",
    "            with open(serialized_results_filename, 'w', encoding='utf-8') as fp:\n",
    "                json.dump(result_dict, fp, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "provaRisultatiStandardScaler = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fold model used: SVC\n",
      "best score: 0.721, best params: {'C': 27.825594022071257, 'gamma': 0.021544346900318846, 'kernel': 'rbf'} test error: 0.769 end fold\n",
      "start fold model used: SVC\n",
      "best score: 0.693, best params: {'C': 166.81005372000593, 'gamma': 0.003593813663804626, 'kernel': 'rbf'} test error: 0.654 end fold\n",
      "start fold model used: SVC\n",
      "best score: 0.692, best params: {'C': 27.825594022071257, 'gamma': 'auto', 'kernel': 'linear'} test error: 0.692 end fold\n",
      "start fold model used: SVC\n",
      "best score: 0.711, best params: {'C': 0.774263682681127, 'gamma': 0.1291549665014884, 'kernel': 'rbf'} test error: 0.615 end fold\n",
      "start fold model used: SVC\n",
      "best score: 0.654, best params: {'C': 0.774263682681127, 'gamma': 'auto', 'kernel': 'linear'} test error: 0.808 end fold\n",
      "start fold model used: DecisionTreeClassifier\n",
      "best score: 0.654, best params: {'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2} test error: 0.538 end fold\n",
      "start fold model used: DecisionTreeClassifier\n",
      "best score: 0.711, best params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'max_leaf_nodes': 5} test error: 0.615 end fold\n",
      "start fold model used: DecisionTreeClassifier\n",
      "best score: 0.673, best params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 100} test error: 0.692 end fold\n",
      "start fold model used: DecisionTreeClassifier\n",
      "best score: 0.625, best params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'max_leaf_nodes': 50} test error: 0.500 end fold\n",
      "start fold model used: DecisionTreeClassifier\n",
      "best score: 0.712, best params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': None} test error: 0.538 end fold\n",
      "start fold model used: RandomForestClassifier\n",
      "best score: 0.692, best params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 10} test error: 0.577 end fold\n",
      "start fold model used: RandomForestClassifier\n",
      "best score: 0.673, best params: {'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': 2, 'n_estimators': 5} test error: 0.615 end fold\n",
      "start fold model used: RandomForestClassifier\n",
      "best score: 0.712, best params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 100, 'n_estimators': 5} test error: 0.500 end fold\n",
      "start fold model used: RandomForestClassifier\n",
      "best score: 0.692, best params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 2, 'n_estimators': 5} test error: 0.692 end fold\n",
      "start fold model used: RandomForestClassifier\n",
      "best score: 0.692, best params: {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 50, 'n_estimators': 10} test error: 0.654 end fold\n",
      "start fold model used: GaussianNB\n",
      "best score: 0.702, best params: {} test error: 0.654 end fold\n",
      "start fold model used: GaussianNB\n",
      "best score: 0.674, best params: {} test error: 0.846 end fold\n",
      "start fold model used: GaussianNB\n",
      "best score: 0.663, best params: {} test error: 0.692 end fold\n",
      "start fold model used: GaussianNB\n",
      "best score: 0.683, best params: {} test error: 0.615 end fold\n",
      "start fold model used: GaussianNB\n",
      "best score: 0.663, best params: {} test error: 0.615 end fold\n",
      "start fold model used: LinearDiscriminantAnalysis\n",
      "best score: 0.597, best params: {} test error: 0.577 end fold\n",
      "start fold model used: LinearDiscriminantAnalysis\n",
      "best score: 0.616, best params: {} test error: 0.769 end fold\n",
      "start fold model used: LinearDiscriminantAnalysis\n",
      "best score: 0.674, best params: {} test error: 0.654 end fold\n",
      "start fold model used: LinearDiscriminantAnalysis\n",
      "best score: 0.635, best params: {} test error: 0.654 end fold\n",
      "start fold model used: LinearDiscriminantAnalysis\n",
      "best score: 0.625, best params: {} test error: 0.692 end fold\n",
      "start fold model used: MLPClassifier\n",
      "best score: 0.673, best params: {'activation': 'identity', 'hidden_layer_sizes': [4, 4], 'max_iter': 5000} test error: 0.769 end fold\n",
      "start fold model used: MLPClassifier\n",
      "best score: 0.702, best params: {'activation': 'identity', 'hidden_layer_sizes': [2], 'max_iter': 5000} test error: 0.654 end fold\n",
      "start fold model used: MLPClassifier\n",
      "best score: 0.731, best params: {'activation': 'identity', 'hidden_layer_sizes': [4, 4], 'max_iter': 5000} test error: 0.577 end fold\n",
      "start fold model used: MLPClassifier\n",
      "best score: 0.730, best params: {'activation': 'logistic', 'hidden_layer_sizes': [4], 'max_iter': 5000} test error: 0.769 end fold\n",
      "start fold model used: MLPClassifier\n",
      "best score: 0.711, best params: {'activation': 'tanh', 'hidden_layer_sizes': [2], 'max_iter': 5000} test error: 0.731 end fold\n"
     ]
    }
   ],
   "source": [
    "add_column_to_results_nuovo(provaRisultatiStandardScaler, 'Totali', 'ProvaRisultatiStandardScaler.json', X_total, y_total, models, grids, logger_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total_with_BMI = dataset[['SESSO', 'ANNI', 'PESO', 'ALTEZZA', 'BMI', 'Tot Testa', 'Tot Torace', 'Tot Addome', 'Tot Scheletro']]\n",
    "y_total_with_BMI = dataset['Mezzo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fold model used: SVC\n",
      "best score: 0.692, best params: {'C': 0.774263682681127, 'gamma': 0.1291549665014884, 'kernel': 'rbf'} test error: 0.769 end fold\n",
      "start fold model used: SVC\n",
      "best score: 0.693, best params: {'C': 166.81005372000593, 'gamma': 0.003593813663804626, 'kernel': 'rbf'} test error: 0.692 end fold\n",
      "start fold model used: SVC\n",
      "best score: 0.683, best params: {'C': 166.81005372000593, 'gamma': 'auto', 'kernel': 'linear'} test error: 0.692 end fold\n",
      "start fold model used: SVC\n",
      "best score: 0.702, best params: {'C': 0.774263682681127, 'gamma': 'auto', 'kernel': 'rbf'} test error: 0.577 end fold\n",
      "start fold model used: SVC\n",
      "best score: 0.682, best params: {'C': 0.774263682681127, 'gamma': 'auto', 'kernel': 'linear'} test error: 0.808 end fold\n",
      "start fold model used: DecisionTreeClassifier\n",
      "best score: 0.683, best params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 5} test error: 0.538 end fold\n",
      "start fold model used: DecisionTreeClassifier\n",
      "best score: 0.682, best params: {'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2} test error: 0.615 end fold\n",
      "start fold model used: DecisionTreeClassifier\n",
      "best score: 0.645, best params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'max_leaf_nodes': 10} test error: 0.692 end fold\n",
      "start fold model used: DecisionTreeClassifier\n",
      "best score: 0.625, best params: {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 50} test error: 0.500 end fold\n",
      "start fold model used: DecisionTreeClassifier\n",
      "best score: 0.673, best params: {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 10} test error: 0.500 end fold\n",
      "start fold model used: RandomForestClassifier\n",
      "best score: 0.644, best params: {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 2, 'n_estimators': 10} test error: 0.500 end fold\n",
      "start fold model used: RandomForestClassifier\n",
      "best score: 0.673, best params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'max_leaf_nodes': 2, 'n_estimators': 50} test error: 0.577 end fold\n",
      "start fold model used: RandomForestClassifier\n",
      "best score: 0.722, best params: {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': 2, 'n_estimators': 5} test error: 0.577 end fold\n",
      "start fold model used: RandomForestClassifier\n",
      "best score: 0.673, best params: {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'max_leaf_nodes': 5, 'n_estimators': 50} test error: 0.615 end fold\n",
      "start fold model used: RandomForestClassifier\n",
      "best score: 0.683, best params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 50, 'n_estimators': 5} test error: 0.731 end fold\n",
      "start fold model used: GaussianNB\n",
      "best score: 0.664, best params: {} test error: 0.769 end fold\n",
      "start fold model used: GaussianNB\n",
      "best score: 0.682, best params: {} test error: 0.692 end fold\n",
      "start fold model used: GaussianNB\n",
      "best score: 0.702, best params: {} test error: 0.615 end fold\n",
      "start fold model used: GaussianNB\n",
      "best score: 0.682, best params: {} test error: 0.731 end fold\n",
      "start fold model used: GaussianNB\n",
      "best score: 0.693, best params: {} test error: 0.692 end fold\n",
      "start fold model used: LinearDiscriminantAnalysis\n",
      "best score: 0.625, best params: {} test error: 0.692 end fold\n",
      "start fold model used: LinearDiscriminantAnalysis\n",
      "best score: 0.673, best params: {} test error: 0.615 end fold\n",
      "start fold model used: LinearDiscriminantAnalysis\n",
      "best score: 0.587, best params: {} test error: 0.654 end fold\n",
      "start fold model used: LinearDiscriminantAnalysis\n",
      "best score: 0.722, best params: {} test error: 0.692 end fold\n",
      "start fold model used: LinearDiscriminantAnalysis\n",
      "best score: 0.634, best params: {} test error: 0.538 end fold\n",
      "start fold model used: MLPClassifier\n",
      "best score: 0.721, best params: {'activation': 'relu', 'hidden_layer_sizes': [4], 'max_iter': 5000} test error: 0.462 end fold\n",
      "start fold model used: MLPClassifier\n",
      "best score: 0.692, best params: {'activation': 'logistic', 'hidden_layer_sizes': [4], 'max_iter': 5000} test error: 0.731 end fold\n",
      "start fold model used: MLPClassifier\n",
      "best score: 0.682, best params: {'activation': 'logistic', 'hidden_layer_sizes': [10], 'max_iter': 5000} test error: 0.692 end fold\n",
      "start fold model used: MLPClassifier\n",
      "best score: 0.626, best params: {'activation': 'relu', 'hidden_layer_sizes': [10, 10], 'max_iter': 5000} test error: 0.654 end fold\n",
      "start fold model used: MLPClassifier\n",
      "best score: 0.731, best params: {'activation': 'tanh', 'hidden_layer_sizes': [6], 'max_iter': 5000} test error: 0.538 end fold\n"
     ]
    }
   ],
   "source": [
    "add_column_to_results_nuovo(provaRisultatiStandardScaler, 'Totali_with_BMI', 'ProvaRisultatiStandardScaler.json', X_total_with_BMI, y_total_with_BMI, models, grids, logger_name=logger_prova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La prima data del dataset è:  1999-10-29T00:00:00.000000000\n"
     ]
    }
   ],
   "source": [
    "date_ordinate = dataset['DATA'].sort_values()\n",
    "prima_data = date_ordinate.values[0]\n",
    "print(\"La prima data del dataset è: \", prima_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "dataset.DATA = dataset.DATA.apply(lambda d: (d - dt.datetime(1970,1,1)).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fold model used: SVC\n",
      "best score: 0.750, best params: {'C': 0.774263682681127, 'gamma': 0.1291549665014884, 'kernel': 'rbf'} test error: 0.692 end fold\n",
      "start fold model used: SVC\n",
      "best score: 0.730, best params: {'C': 4.641588833612782, 'gamma': 0.021544346900318846, 'kernel': 'rbf'} test error: 0.846 end fold\n",
      "start fold model used: SVC\n",
      "best score: 0.760, best params: {'C': 0.774263682681127, 'gamma': 0.021544346900318846, 'kernel': 'rbf'} test error: 0.769 end fold\n",
      "start fold model used: SVC\n",
      "best score: 0.711, best params: {'C': 4.641588833612782, 'gamma': 0.021544346900318846, 'kernel': 'rbf'} test error: 0.846 end fold\n",
      "start fold model used: SVC\n",
      "best score: 0.750, best params: {'C': 0.774263682681127, 'gamma': 'auto', 'kernel': 'rbf'} test error: 0.731 end fold\n",
      "start fold model used: DecisionTreeClassifier\n",
      "best score: 0.797, best params: {'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None} test error: 0.731 end fold\n",
      "start fold model used: DecisionTreeClassifier\n",
      "best score: 0.711, best params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None} test error: 0.846 end fold\n",
      "start fold model used: DecisionTreeClassifier\n",
      "best score: 0.770, best params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'max_leaf_nodes': 5} test error: 0.385 end fold\n",
      "start fold model used: DecisionTreeClassifier\n",
      "best score: 0.750, best params: {'criterion': 'gini', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None} test error: 0.808 end fold\n",
      "start fold model used: DecisionTreeClassifier\n",
      "best score: 0.741, best params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 50} test error: 0.615 end fold\n",
      "start fold model used: RandomForestClassifier\n",
      "best score: 0.721, best params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 100, 'n_estimators': 10} test error: 0.692 end fold\n",
      "start fold model used: RandomForestClassifier\n",
      "best score: 0.799, best params: {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 2, 'n_estimators': 5} test error: 0.577 end fold\n",
      "start fold model used: RandomForestClassifier\n",
      "best score: 0.778, best params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'max_leaf_nodes': 10, 'n_estimators': 200} test error: 0.692 end fold\n",
      "start fold model used: RandomForestClassifier\n",
      "best score: 0.798, best params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'n_estimators': 100} test error: 0.692 end fold\n",
      "start fold model used: RandomForestClassifier\n",
      "best score: 0.778, best params: {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': 5, 'n_estimators': 10} test error: 0.692 end fold\n",
      "start fold model used: GaussianNB\n",
      "best score: 0.701, best params: {} test error: 0.654 end fold\n",
      "start fold model used: GaussianNB\n",
      "best score: 0.730, best params: {} test error: 0.731 end fold\n",
      "start fold model used: GaussianNB\n",
      "best score: 0.750, best params: {} test error: 0.846 end fold\n",
      "start fold model used: GaussianNB\n",
      "best score: 0.741, best params: {} test error: 0.615 end fold\n",
      "start fold model used: GaussianNB\n",
      "best score: 0.731, best params: {} test error: 0.769 end fold\n",
      "start fold model used: LinearDiscriminantAnalysis\n",
      "best score: 0.722, best params: {} test error: 0.615 end fold\n",
      "start fold model used: LinearDiscriminantAnalysis\n",
      "best score: 0.682, best params: {} test error: 0.769 end fold\n",
      "start fold model used: LinearDiscriminantAnalysis\n",
      "best score: 0.750, best params: {} test error: 0.654 end fold\n",
      "start fold model used: LinearDiscriminantAnalysis\n",
      "best score: 0.683, best params: {} test error: 0.731 end fold\n",
      "start fold model used: LinearDiscriminantAnalysis\n",
      "best score: 0.731, best params: {} test error: 0.808 end fold\n",
      "start fold model used: MLPClassifier\n",
      "best score: 0.769, best params: {'activation': 'relu', 'hidden_layer_sizes': [2], 'max_iter': 5000} test error: 0.654 end fold\n",
      "start fold model used: MLPClassifier\n",
      "best score: 0.818, best params: {'activation': 'identity', 'hidden_layer_sizes': [2], 'max_iter': 5000} test error: 0.615 end fold\n",
      "start fold model used: MLPClassifier\n",
      "best score: 0.722, best params: {'activation': 'identity', 'hidden_layer_sizes': [4], 'max_iter': 5000} test error: 0.769 end fold\n",
      "start fold model used: MLPClassifier\n",
      "best score: 0.750, best params: {'activation': 'logistic', 'hidden_layer_sizes': [4], 'max_iter': 5000} test error: 0.769 end fold\n",
      "start fold model used: MLPClassifier\n",
      "best score: 0.780, best params: {'activation': 'tanh', 'hidden_layer_sizes': [2], 'max_iter': 5000} test error: 0.769 end fold\n"
     ]
    }
   ],
   "source": [
    "X_total_with_data = dataset[['DATA', 'SESSO', 'ANNI', 'PESO', 'ALTEZZA', 'Tot Testa', 'Tot Torace', 'Tot Addome', 'Tot Scheletro']]\n",
    "y_total_with_data = dataset['Mezzo']\n",
    "\n",
    "add_column_to_results_nuovo(provaRisultatiStandardScaler, 'Totali_with_DATA', 'ProvaRisultatiStandardScaler.json', X_total_with_data, y_total_with_data, models, grids, logger_name=logger_prova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
