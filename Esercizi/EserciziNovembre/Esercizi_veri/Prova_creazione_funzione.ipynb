{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer, load_iris\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from statistics import mean\n",
    "from scikitplot.metrics import plot_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import logging\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addestraSVC(X, y, c, gamma, kernel, dim):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=30, stratify=y)\n",
    "    \n",
    "    #standardizzo i dati\n",
    "    sc = StandardScaler()\n",
    "    X_train_standardizzato = sc.fit_transform(X_train)\n",
    "    X_test_standardizzato = sc.fit_transform(X_test)\n",
    "    \n",
    "    #applico la riduzione della dimensionalita'\n",
    "    pca = PCA(n_components=dim)\n",
    "    \n",
    "    X_train_ridotto = pca.fit_transform(X_train_standardizzato)\n",
    "    X_test_ridotto = pca.fit_transform(X_test_standardizzato)\n",
    "    \n",
    "    #addestro la SVC\n",
    "    model = SVC(gamma = gamma, C=c, kernel = kernel)\n",
    "    model.fit(X_train_ridotto, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test_ridotto)\n",
    "    \n",
    "    #calcolo lo score\n",
    "    scoreStandardizzato = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    #Non standardizzo i  dati ma riduco subito la dimensionalita' e addestro la SVC\n",
    "    X_train_ridotto = pca.fit_transform(X_train)\n",
    "    X_test_ridotto = pca.fit_transform(X_test)\n",
    "    \n",
    "    model = SVC(gamma = gamma, C=c, kernel = kernel)\n",
    "    model.fit(X_train_ridotto, y_train)\n",
    "    \n",
    "    y_pred_not_standardizzato = model.predict(X_test_ridotto)\n",
    "    \n",
    "    #calcolo lo score\n",
    "    score_not_standardizzato = accuracy_score(y_test, y_pred_not_standardizzato)\n",
    "    \n",
    "    if scoreStandardizzato > score_not_standardizzato:\n",
    "        return(f'Lo score e stato calcolato standardizzando i dati, score: {scoreStandardizzato}')\n",
    "    else:\n",
    "        return(f'Lo score e stato calcolato non standardizzando i dati, score: {score_not_standardizzato}')\n",
    "\n",
    "def addrestraDecisionTreeClassifier(X, y, criterion, dim):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=30, stratify=y)\n",
    "    \n",
    "    #standardizzo i dati\n",
    "    sc = StandardScaler()\n",
    "    X_train_standardizzato = sc.fit_transform(X_train)\n",
    "    X_test_standardizzato = sc.fit_transform(X_test)\n",
    "    \n",
    "    #applico la riduzione della dimensionalita'\n",
    "    pca = PCA(n_components=dim)\n",
    "    \n",
    "    X_train_ridotto = pca.fit_transform(X_train_standardizzato)\n",
    "    X_test_ridotto = pca.fit_transform(X_test_standardizzato)\n",
    "    \n",
    "    #addestro un DecisionTree\n",
    "    model = DecisionTreeClassifier(criterion=criterion)\n",
    "    model.fit(X_train_ridotto, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test_ridotto)\n",
    "    \n",
    "    #calcolo lo score\n",
    "    scoreStandardizzato = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    #Non standardizzo i  dati ma riduco subito la dimensionalita' e addestro un DecisionTree\n",
    "    X_train_ridotto = pca.fit_transform(X_train)\n",
    "    X_test_ridotto = pca.fit_transform(X_test)\n",
    "    \n",
    "    model = DecisionTreeClassifier(criterion=criterion)\n",
    "    model.fit(X_train_ridotto, y_train)\n",
    "    \n",
    "    y_pred_not_standardizzato = model.predict(X_test_ridotto)\n",
    "    \n",
    "    #calcolo lo score\n",
    "    score_not_standardizzato = accuracy_score(y_test, y_pred_not_standardizzato)\n",
    "    \n",
    "    if scoreStandardizzato > score_not_standardizzato:\n",
    "        return(f'Lo score e stato calcolato standardizzando i dati, score: {scoreStandardizzato}')\n",
    "    else:\n",
    "        return(f'Lo score e stato calcolato non standardizzando i dati, score: {score_not_standardizzato}')\n",
    "\n",
    "def addestraRandomForestClassifier(X, y, n_estimators, dim):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=30, stratify=y)\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    \n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.fit_transform(X_test)\n",
    "    \n",
    "    pca = PCA(n_components=dim)\n",
    "    \n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.fit_transform(X_test)\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=n_estimators)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "def addestraLinearDiscriminantAnalysis(X, y, solver, dim):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=30, stratify=y)\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    \n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.fit_transform(X_test)\n",
    "    \n",
    "    pca = PCA(n_components=dim)\n",
    "    \n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.fit_transform(X_test)\n",
    "    \n",
    "    model = LinearDiscriminantAnalysis(solver=solver)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "def addestraNaiveBayes(X, y, dim):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=30, stratify=y)\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    \n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.fit_transform(X_test)\n",
    "    \n",
    "    pca = PCA(n_components=dim)\n",
    "    \n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.fit_transform(X_test)\n",
    "    \n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "def addestraMLPClassifier(X, y, activation, learning_rate, dim, hidden_layer_sizes, max_iter):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=30, stratify=y)\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    \n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.fit_transform(X_test)\n",
    "    \n",
    "    pca = PCA(n_components=dim)\n",
    "    \n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.fit_transform(X_test)\n",
    "    \n",
    "    model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, max_iter=max_iter, activation=activation, learning_rate=learning_rate)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "#funzione che calcola il valore degli iperparametri per il modello dato in input\n",
    "def trovaIperparametri(X, y, model, numero_dimensioni):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=30, stratify=y)\n",
    "\n",
    "    if model == SVC:\n",
    "        steps = [\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('reduce_dim', PCA()),\n",
    "            ('SVM', SVC()), \n",
    "        ]\n",
    "\n",
    "        pipeline = Pipeline(steps)\n",
    "\n",
    "        valori_C = np.arange(0.1, 1.0, 0.1)\n",
    "        valori_gamma = [0.1, 0.01]\n",
    "        valori_kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "        params = { 'SVM__C': valori_C,\n",
    "                  'SVM__gamma': valori_gamma,\n",
    "                  'SVM__kernel': valori_kernel,\n",
    "                  'reduce_dim__n_components': np.arange(1, numero_dimensioni, 1),\n",
    "                }\n",
    "    elif model == DecisionTreeClassifier:\n",
    "        \n",
    "        steps = [\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('reduce_dim', PCA()),\n",
    "            ('tree', DecisionTreeClassifier()),\n",
    "        ]\n",
    "        \n",
    "        pipeline= Pipeline(steps)\n",
    "        \n",
    "        params = {'reduce_dim__n_components': np.arange(1, numero_dimensioni, 1),\n",
    "                  'tree__criterion': ['gini', 'entropy'],\n",
    "                 }\n",
    "    \n",
    "    elif model == RandomForestClassifier:\n",
    "        \n",
    "        steps = [\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('reduce_dim', PCA()),\n",
    "            ('random_forest', RandomForestClassifier()),\n",
    "        ]\n",
    "        \n",
    "        pipeline = Pipeline(steps)\n",
    "        \n",
    "        params = {'reduce_dim__n_components': np.arange(1, numero_dimensioni, 1),\n",
    "                  'random_forest__n_estimators': np.arange(10, 100, 10),\n",
    "                 }\n",
    "    \n",
    "    elif model == LinearDiscriminantAnalysis:\n",
    "        \n",
    "        steps = [\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('reduce_dim', PCA()),\n",
    "            ('linear_discriminant_analysis', LinearDiscriminantAnalysis()),\n",
    "        ]\n",
    "        \n",
    "        pipeline = Pipeline(steps)\n",
    "        \n",
    "        params = {'reduce_dim__n_components': np.arange(1, numero_dimensioni, 1),\n",
    "                  'linear_discriminant_analysis__solver': ['svd', 'lsqr', 'eigen'],\n",
    "                  \n",
    "                 }\n",
    "    elif model == GaussianNB:\n",
    "        steps = [\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('reduce_dim', PCA()),\n",
    "            ('linear_discriminant_analysis', LinearDiscriminantAnalysis()),\n",
    "        ]\n",
    "        \n",
    "        pipeline = Pipeline(steps)\n",
    "        \n",
    "        params = {'reduce_dim__n_components': np.arange(1, numero_dimensioni, 1),\n",
    "\n",
    "                 }\n",
    "    elif model == MLPClassifier:\n",
    "        \n",
    "        steps = [\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('reduce_dim', PCA()),\n",
    "            ('mlpClassifier', MLPClassifier(hidden_layer_sizes=(150, 100, 50), max_iter=300)), #impostate cosi per provare a vedere se trova gli altri iperparametri\n",
    "        ]\n",
    "        \n",
    "        pipeline = Pipeline(steps)\n",
    "        \n",
    "        params = {'reduce_dim__n_components': np.arange(1, numero_dimensioni, 1),\n",
    "                  'mlpClassifier__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                  'mlpClassifier__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "                  \n",
    "                 }\n",
    "        \n",
    "    grid = GridSearchCV(pipeline, param_grid=params, cv=3)\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    return grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_breast_cancer()\n",
    "X = dataset['data']\n",
    "y = dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVM__C': 0.8,\n",
       " 'SVM__gamma': 0.1,\n",
       " 'SVM__kernel': 'linear',\n",
       " 'reduce_dim__n_components': 9}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trovaIperparametri(X, y, model=SVC, numero_dimensioni=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lo score e stato calcolato standardizzando i dati, score: 0.9736842105263158'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addestraSVC(X, y,  0.8, 0.1, 'linear', 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reduce_dim__n_components': 19, 'tree__criterion': 'gini'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trovaIperparametri(X, y, DecisionTreeClassifier, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lo score e stato calcolato standardizzando i dati, score: 0.9473684210526315'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addrestraDecisionTreeClassifier(X, y, 'gini', 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_forest__n_estimators': 20, 'reduce_dim__n_components': 6}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trovaIperparametri(X, y, RandomForestClassifier, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9385964912280702"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addestraRandomForestClassifier(X, y, n_estimators=20, dim=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear_discriminant_analysis__solver': 'svd', 'reduce_dim__n_components': 14}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trovaIperparametri(X, y, LinearDiscriminantAnalysis, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956140350877193"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addestraLinearDiscriminantAnalysis(X, y, solver='svd', dim=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reduce_dim__n_components': 14}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trovaIperparametri(X=X, y=y, model=GaussianNB, numero_dimensioni=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.868421052631579"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addestraNaiveBayes(X=X, y=y, dim=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mlpClassifier__activation': 'logistic',\n",
       " 'mlpClassifier__learning_rate': 'constant',\n",
       " 'reduce_dim__n_components': 9}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trovaIperparametri(X, y, MLPClassifier, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addestraMLPClassifier(X=X, y=y, hidden_layer_sizes=(150, 50), max_iter=100, learning_rate='constant', activation='logistic', dim=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
