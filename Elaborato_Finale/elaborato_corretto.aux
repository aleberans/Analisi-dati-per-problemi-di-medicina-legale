\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\babel@aux{italian}{}
\babel@aux{italian}{}
\@writefile{toc}{\contentsline {chapter}{Ringraziamenti}{ii}{chapter*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Indice}{iii}{chapter*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduzione}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{cap:introduzione}{{1}{1}{Introduzione}{chapter.1}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Machine Learning}{2}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Come funziona il Machine Learning}{2}{section.2.1}\protected@file@percent }
\newlabel{ComefunzionailMachineLearning}{{2.1}{2}{Come funziona il Machine Learning}{section.2.1}{}}
\citation{SupervisedMachineLearning}
\citation{SupervisedMachineLearning}
\citation{Introductiontodatamining}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Apprendimento supervisionato}{3}{subsection.2.1.1}\protected@file@percent }
\newlabel{apprendimentoSupervisionato}{{2.1.1}{3}{Apprendimento supervisionato}{subsection.2.1.1}{}}
\citation{LectureNotesNg}
\citation{LectureNotesNg}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1.1}Support Vector Machine}{4}{subsubsection.2.1.1.1}\protected@file@percent }
\newlabel{sec:SVC}{{2.1.1.1}{4}{Support Vector Machine}{subsubsection.2.1.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Iperpiano e margine\relax }}{5}{figure.caption.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Infinite rette possono separare gli elementi\relax }}{6}{figure.caption.4}\protected@file@percent }
\citation{LectureNotesNg}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Non sempre \IeC {\`e} possibile dividere i dati linearmente\relax }}{7}{figure.caption.5}\protected@file@percent }
\citation{DataMiningandKnowledgeDiscoveryHandbook}
\citation{Introductiontodatamining}
\citation{Introductiontodatamining}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1.2}Decision Tree Classifier}{8}{subsubsection.2.1.1.2}\protected@file@percent }
\citation{DataMiningandKnowledgeDiscoveryHandbook}
\citation{RandomForest}
\citation{Mitchell97}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1.3}Random Forest Classifier}{9}{subsubsection.2.1.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1.4}Gaussian Naive Bayes}{9}{subsubsection.2.1.1.4}\protected@file@percent }
\citation{multilayerPerceptron}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1.5}Linear Discriminat Analysis}{10}{subsubsection.2.1.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1.6}Reti Neurali Multi-Strato}{10}{subsubsection.2.1.1.6}\protected@file@percent }
\newlabel{MLP}{{2.1.1.6}{10}{Reti Neurali Multi-Strato}{subsubsection.2.1.1.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Visualizzazione di un percettrone\relax }}{11}{figure.caption.6}\protected@file@percent }
\citation{multilayerPerceptron}
\citation{unsupervisedlearning}
\citation{unsupervisedlearning}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Visualizzazione di una rete multistrato; in rosso il livello di input, al centro il livello hidden, in verde a destra il livello di output\relax }}{12}{figure.caption.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Apprendimento non supervisionato}{12}{subsection.2.1.2}\protected@file@percent }
\citation{semisupervised}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Apprendimento per rinforzo}{13}{subsection.2.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Apprendimento semi supervisionato}{13}{subsection.2.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Dataset}{14}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Iris}{14}{section.3.1}\protected@file@percent }
\newlabel{iris}{{3.1}{14}{Iris}{section.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Visualizzazione di un estratto del dataset Iris\relax }}{14}{figure.caption.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Incidenti Stradali}{15}{section.3.2}\protected@file@percent }
\newlabel{incidentiStradali}{{3.2}{15}{Incidenti Stradali}{section.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Suddivisione caratteristiche dettagliate\relax }}{15}{figure.caption.9}\protected@file@percent }
\citation{shalevshwartz2014understanding}
\citation{pca}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Riduzione della Dimensionalit\IeC {\`a}}{16}{section.3.3}\protected@file@percent }
\newlabel{sec:riduzione}{{3.3}{16}{Riduzione della Dimensionalit√†}{section.3.3}{}}
\citation{pcaFigura}
\citation{pcaFigura}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}PCA}{17}{subsection.3.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Dimensioni trovate tramite PCA \cite  {pcaFigura}\relax }}{17}{figure.caption.10}\protected@file@percent }
\citation{t-SNE}
\citation{t-SNE}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}t-SNE}{19}{subsection.3.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Grafici della densit\IeC {\`a} delle distribuzioni gaussiana ( curva verde), e t-Student (curva blu). La forma della distribuzione t-Student \IeC {\`e} data dai gradi di libert\IeC {\`a} che si riferiscono al numero di osservazioni indipendenti all'interno dei dati\relax }}{19}{figure.caption.11}\protected@file@percent }
\citation{scikit-learn}
\citation{jupyter}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Esperimenti}{21}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{cap3}{{4}{21}{Esperimenti}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Pre Processsing}{21}{section.4.1}\protected@file@percent }
\citation{scikit-learn}
\citation{scikit-learn}
\citation{scikit-learn}
\citation{scikit-learn}
\citation{Raschka2018ModelEM}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Scalare i dati}{22}{subsection.4.1.1}\protected@file@percent }
\citation{scikit-learn}
\citation{scikit-learn}
\citation{scikit-learn}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Model Selection}{23}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Scelta degli Iperparametri}{23}{subsection.4.2.1}\protected@file@percent }
\newlabel{iperparametri}{{4.2.1}{23}{Scelta degli Iperparametri}{subsection.4.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Errore di Generalizzazione}{24}{section.4.3}\protected@file@percent }
\newlabel{sec:errore}{{4.3}{24}{Errore di Generalizzazione}{section.4.3}{}}
\citation{TheElementsofStatisticalLearning}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Cross Validation}{25}{section.4.4}\protected@file@percent }
\newlabel{cv}{{4.4}{25}{Cross Validation}{section.4.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Risultati Ottenuti}{26}{section.4.5}\protected@file@percent }
\newlabel{sec:risultati}{{4.5}{26}{Risultati Ottenuti}{section.4.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Analisi dei Risultati}{30}{section.4.6}\protected@file@percent }
\bibstyle{unsrt}
\bibdata{bibliografia}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusioni}{31}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{SupervisedMachineLearning}{1}
\bibcite{Introductiontodatamining}{2}
\bibcite{LectureNotesNg}{3}
\bibcite{DataMiningandKnowledgeDiscoveryHandbook}{4}
\bibcite{RandomForest}{5}
\bibcite{Mitchell97}{6}
\bibcite{multilayerPerceptron}{7}
\bibcite{unsupervisedlearning}{8}
\bibcite{semisupervised}{9}
\bibcite{shalevshwartz2014understanding}{10}
\bibcite{pca}{11}
\bibcite{pcaFigura}{12}
\bibcite{t-SNE}{13}
\bibcite{scikit-learn}{14}
\bibcite{jupyter}{15}
\bibcite{Raschka2018ModelEM}{16}
\bibcite{TheElementsofStatisticalLearning}{17}
\@writefile{toc}{\contentsline {chapter}{Bibliografia}{33}{chapter*.24}\protected@file@percent }
